{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carolyn-Ha/MDST/blob/main/20_4_lec20_channels_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCQYWQiil8Fe"
      },
      "source": [
        "**Notebook credit**: Based on the original D2L notebook [here](https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/chapter_convolutional-neural-networks/channels.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "SlnOIuXxl8Fi"
      },
      "source": [
        "# Multiple Input and Multiple Output Channels\n",
        "\n",
        "While we have described the multiple channels\n",
        "that comprise each image (e.g., color images have the standard RGB channels\n",
        "to indicate the amount of red, green and blue) and convolutional layers for multiple channels before,\n",
        "until now, we simplified all of our numerical examples\n",
        "by working with just a single input and a single output channel.\n",
        "This has allowed us to think of our inputs, convolution kernels,\n",
        "and outputs each as two-dimensional tensors.\n",
        "\n",
        "When we add channels into the mix,\n",
        "our inputs and hidden representations\n",
        "both become three-dimensional tensors.\n",
        "For example, each RGB input image has shape $3\\times h\\times w$.\n",
        "We refer to this axis, with a size of 3, as the *channel* dimension.\n",
        "In this section, we will take a deeper look\n",
        "at convolution kernels with multiple input and multiple output channels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Multiple Input Channels\n",
        "\n",
        "When the input data contain multiple channels,\n",
        "we need to construct a convolution kernel\n",
        "with the same number of input channels as the input data,\n",
        "so that it can perform cross-correlation with the input data.\n",
        "Assuming that the number of channels for the input data is $c_i$,\n",
        "the number of input channels of the convolution kernel also needs to be $c_i$. If our convolution kernel's window shape is $k_h\\times k_w$,\n",
        "then when $c_i=1$, we can think of our convolution kernel\n",
        "as just a two-dimensional tensor of shape $k_h\\times k_w$.\n",
        "\n",
        "However, when $c_i>1$, we need a kernel\n",
        "that contains a tensor of shape $k_h\\times k_w$ for *every* input channel. Concatenating these $c_i$ tensors together\n",
        "yields a convolution kernel of shape $c_i\\times k_h\\times k_w$.\n",
        "Since the input and convolution kernel each have $c_i$ channels,\n",
        "we can perform a cross-correlation operation\n",
        "on the two-dimensional tensor of the input\n",
        "and the two-dimensional tensor of the convolution kernel\n",
        "for each channel, adding the $c_i$ results together\n",
        "(summing over the channels)\n",
        "to yield a two-dimensional tensor.\n",
        "This is the result of a two-dimensional cross-correlation\n",
        "between a multi-channel input and\n",
        "a multi-input-channel convolution kernel.\n",
        "\n",
        "In the figure below, we demonstrate an example\n",
        "of a two-dimensional cross-correlation with two input channels.\n",
        "The shaded portions are the first output element\n",
        "as well as the input and kernel tensor elements used for the output computation:\n",
        "$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$.\n",
        "\n",
        "![Cross-correlation computation with 2 input channels.](https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/img/conv-multi-in.svg?raw=1)\n",
        "\n",
        "\n",
        "To make sure we really understand what is going on here,\n",
        "we can (**implement cross-correlation operations with multiple input channels**) ourselves.\n",
        "Notice that all we are doing is performing one cross-correlation operation\n",
        "per channel and then adding up the results.\n"
      ],
      "metadata": {
        "id": "R88a1vE-AuRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Notes***\n",
        "- with channels: yields a convolution kernel of shape $c_i\\times k_h\\times k_w$.\n",
        "  - additional dimension other than height, width: will be the number of channels\n",
        "\n",
        "- use different kernels for different channels => same size kernel\n",
        "  - elementwise multiplication -> add up everything together\n",
        "\n",
        "- if we have 2 channels of input -> will have 2 channels of kernel\n",
        "- if we have same number of input channels for the kernel -> do element wise and channel wise convolution (number of input channels should match the number of kernels)\n",
        "\n",
        "\n",
        "\n",
        "**[cf]**\n",
        "- kernel: small matrix that slides over the input data during convolution, extracting local patterns\n",
        "- channel: different feature maps produced by applying multiple kernels to the input data => Each channel captures different aspects or features of the input, and the combination of channels forms the output tensor of a convolutional layer"
      ],
      "metadata": {
        "id": "F1tD6Mth-TfO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 4,
        "tab": [
          "tensorflow"
        ],
        "id": "zOJ4ubXFl8Fk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def corr2d(X, K):\n",
        "    # Compute 2D cross-correlation => 2D cross-correlation of a 2D input tensor X with a 2D kernel K\n",
        "    h, w = K.shape\n",
        "    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))\n",
        "      #(1) initializing output tensor Y with zeros: where the dimension of Y are determined by the shape of X and K\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i,j].assign(tf.reduce_sum(\n",
        "                X[i : i + h, j: j + w]*K\n",
        "            ))\n",
        "            #(2) computing cross-correlation:\n",
        "              # -element-wise product of the corresponding elements in the input tensor X and the kernel K\n",
        "              # -summing up the results.\n",
        "    return Y\n",
        "\n",
        "\n",
        "def corr2d_multi_in(X, K):\n",
        "    # => multi-input 2D cross-correlation.\n",
        "    # first iterate through the 0th dimension (channel dimension) of 'X' and 'K,\n",
        "    # then, add them together\n",
        "    return tf.reduce_sum([corr2d(x,k) for x,k in zip(X,K)], axis=0)\n",
        "      #(1) iterate over every single x,k in zip(X,K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 5,
        "id": "6UMugpq7l8Fl"
      },
      "source": [
        "We can construct the input tensor `X` and the kernel tensor `K`\n",
        "corresponding to the values in the figure above\n",
        "to (**validate the output**) of the cross-correlation operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 6,
        "tab": [
          "tensorflow"
        ],
        "id": "EaPn_vIcl8Fl",
        "outputId": "476a272a-62f1-4f61-ff8c-b7269d17d0a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 56.,  72.],\n",
              "       [104., 120.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "X = tf.constant([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
        "                 [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
        "K = tf.constant([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
        "\n",
        "corr2d_multi_in(X, K).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 7,
        "id": "QAZdPo_Tl8Fm"
      },
      "source": [
        "## Multiple Output Channels\n",
        "\n",
        "\n",
        "Regardless of the number of input channels,\n",
        "so far we always ended up with one output channel.\n",
        "However, as we discussed before,\n",
        "it turns out to be essential to have multiple channels at each layer.\n",
        "In the most popular neural network architectures,\n",
        "we actually increase the channel dimension\n",
        "as we go higher up in the neural network,\n",
        "typically downsampling to trade off spatial resolution\n",
        "for greater *channel depth*.\n",
        "Intuitively, you could think of each channel\n",
        "as responding to some different set of features.\n",
        "Reality is a bit more complicated than the most naive interpretations of this intuition since representations are not learned independent but are rather optimized to be jointly useful.\n",
        "So it may not be that a single channel learns an edge detector but rather that some direction in channel space corresponds to detecting edges.\n",
        "\n",
        "\n",
        "Denote by $c_i$ and $c_o$ the number\n",
        "of input and output channels, respectively,\n",
        "and let $k_h$ and $k_w$ be the height and width of the kernel.\n",
        "To get an output with multiple channels,\n",
        "we can create a kernel tensor\n",
        "of shape $c_i\\times k_h\\times k_w$\n",
        "for *every* output channel.\n",
        "We concatenate them on the output channel dimension,\n",
        "so that the shape of the convolution kernel\n",
        "is $c_o\\times c_i\\times k_h\\times k_w$.\n",
        "In cross-correlation operations,\n",
        "the result on each output channel is calculated\n",
        "from the convolution kernel corresponding to that output channel\n",
        "and takes input from all channels in the input tensor.\n",
        "\n",
        "We implement a cross-correlation function\n",
        "to [**calculate the output of multiple channels**] as shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 8,
        "tab": [
          "tensorflow"
        ],
        "id": "7q7KIy1zl8Fn"
      },
      "outputs": [],
      "source": [
        "def corr2d_multi_in_out(X, K):\n",
        "    # iterate through the 0th dimension of 'K' --- output channel\n",
        "    # each time, perofrm cross-correlation oeprations with input 'X', which can have multiple input channels\n",
        "    # all of the results are stacked together\n",
        "    return tf.stack([corr2d_multi_in(X, k) for k in K])\n",
        "      #(1) going to iterate the operation for every output kernel K => stack them all together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 9,
        "id": "uXoHmlRel8Fn"
      },
      "source": [
        "We construct a convolution kernel with 3 output channels\n",
        "by concatenating the kernel tensor `K` with `K+1`\n",
        "(plus one for each element in `K`) and `K+2`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "tensorflow"
        ],
        "id": "bSGSwKyfl8Fo",
        "outputId": "743626ac-648d-4563-b9c9-ad384ff15801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([3, 2, 2, 2]),\n",
              " <tf.Tensor: shape=(3, 2, 2, 2), dtype=float32, numpy=\n",
              " array([[[[0., 1.],\n",
              "          [2., 3.]],\n",
              " \n",
              "         [[1., 2.],\n",
              "          [3., 4.]]],\n",
              " \n",
              " \n",
              "        [[[1., 2.],\n",
              "          [3., 4.]],\n",
              " \n",
              "         [[2., 3.],\n",
              "          [4., 5.]]],\n",
              " \n",
              " \n",
              "        [[[2., 3.],\n",
              "          [4., 5.]],\n",
              " \n",
              "         [[3., 4.],\n",
              "          [5., 6.]]]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "K = tf.stack((K, K+1, K+2))\n",
        "  #(1) creating 2 new kernels for the other 2 output channels => by adding 1 to every single one of them\n",
        "K.shape, K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 11,
        "id": "T_xSIs-gl8Fo"
      },
      "source": [
        "Below, we perform cross-correlation operations\n",
        "on the input tensor `X` with the kernel tensor `K`.\n",
        "Now the output contains 3 channels.\n",
        "The result of the first channel is consistent\n",
        "with the result of the previous input tensor `X`\n",
        "and the multi-input channel,\n",
        "single-output channel kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 12,
        "tab": [
          "tensorflow"
        ],
        "id": "Hpw6yK_ol8Fo",
        "outputId": "d90c22d0-1872-448a-835e-192b019d6a74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n",
              "array([[[ 56.,  72.],\n",
              "        [104., 120.]],\n",
              "\n",
              "       [[ 76., 100.],\n",
              "        [148., 172.]],\n",
              "\n",
              "       [[ 96., 128.],\n",
              "        [192., 224.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "corr2d_multi_in_out(X, K)\n",
        "  #(1) doing the operation for every single output channels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Notes***\n",
        "- it would not be the case that a single channel learns an edge detector <-> rather some direction in channel space is corresponding to detecting edges\n",
        "  - detectors: going to be jointly used to do an edge detector\n",
        "  - what we did for single kernel: going to repeat this for every single kernel\n",
        "  - whole dimension: $c_o\\times c_i\\times k_h\\times k_w$."
      ],
      "metadata": {
        "id": "Z6C7NsKyawrV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 13,
        "id": "sAf-V2kvl8Fp"
      },
      "source": [
        "## $1\\times 1$ Convolutional Layer\n",
        "\n",
        "At first, a [**$1 \\times 1$ convolution**], i.e., $k_h = k_w = 1$,\n",
        "does not seem to make much sense.\n",
        "After all, a convolution correlates adjacent pixels.\n",
        "A $1 \\times 1$ convolution obviously does not.\n",
        "Nonetheless, they are popular operations that are sometimes included\n",
        "in the designs of complex deep networks.\n",
        "Let us see in some detail what it actually does.\n",
        "\n",
        "Because the minimum window is used,\n",
        "the $1\\times 1$ convolution loses the ability\n",
        "of larger convolutional layers\n",
        "to recognize patterns consisting of interactions\n",
        "among adjacent elements in the height and width dimensions.\n",
        "The only computation of the $1\\times 1$ convolution occurs\n",
        "on the channel dimension.\n",
        "\n",
        "Figure below shows the cross-correlation computation\n",
        "using the $1\\times 1$ convolution kernel\n",
        "with 3 input channels and 2 output channels.\n",
        "Note that the inputs and outputs have the same height and width.\n",
        "Each element in the output is derived\n",
        "from a linear combination of elements *at the same position*\n",
        "in the input image.\n",
        "You could think of the $1\\times 1$ convolutional layer\n",
        "as constituting a fully-connected layer applied at every single pixel location\n",
        "to transform the $c_i$ corresponding input values into $c_o$ output values.\n",
        "Because this is still a convolutional layer,\n",
        "the weights are tied across pixel location.\n",
        "Thus the $1\\times 1$ convolutional layer requires $c_o\\times c_i$ weights\n",
        "(plus the bias).\n",
        "\n",
        "\n",
        "![The cross-correlation computation uses the $1\\times 1$ convolution kernel with 3 input channels and 2 output channels. The input and output have the same height and width.](https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/img/conv-1x1.svg?raw=1)\n",
        "\n",
        "Let us check whether this works in practice:\n",
        "we implement a $1 \\times 1$ convolution\n",
        "using a fully-connected layer.\n",
        "The only thing is that we need to make some adjustments\n",
        "to the data shape before and after the matrix multiplication.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 14,
        "tab": [
          "tensorflow"
        ],
        "id": "3TkumG3bl8Fp"
      },
      "outputs": [],
      "source": [
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "    c_i, h, w = X.shape\n",
        "      #(1) getting the number of input channels\n",
        "    c_o = K.shape[0]\n",
        "      #(2) getting the number of output channels\n",
        "    X = tf.reshape(X, (c_i, h*w))\n",
        "      #(3) summing together, collapsing the input channel dimension\n",
        "    K = tf.reshape(K, (c_o, c_i))\n",
        "    # matrix multiplication in the fully connected layer\n",
        "    Y = tf.matmul(K, X)\n",
        "    return tf.reshape(Y, (c_o, h, w))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 15,
        "id": "vXfnEj05l8Fp"
      },
      "source": [
        "When performing $1\\times 1$ convolution,\n",
        "the above function is equivalent to the previously implemented cross-correlation function `corr2d_multi_in_out`.\n",
        "Let us check this with some sample data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 17,
        "tab": [
          "tensorflow"
        ],
        "id": "U8BBbTxZl8Fp"
      },
      "outputs": [],
      "source": [
        "X = tf.random.normal((3,3,3))\n",
        "K = tf.random.normal((2,3,1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 18,
        "tab": [
          "tensorflow"
        ],
        "id": "E0SbQSWwl8Fq"
      },
      "outputs": [],
      "source": [
        "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
        "Y2 = corr2d_multi_in_out(X, K)\n",
        "assert float(tf.reduce_sum(tf.abs(Y1 - Y2))) < 1e-6\n",
        "  #(1) asserting true: eventhough I have a different implementation,\n",
        "    # this is a customized matrix multiplication interpretation of the specific 1-by-1 convolution layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Notes***\n",
        "- having 1*1 kernel = looking at 1-by-1 patch: meaning that every single patch I'm looking at is one pixel\n",
        "  - thus no locality: why would I need to invoke that in the first place\n",
        "  - input & output have same height and width: since I'm using 1*1 patch\n",
        "- it's going to be a fully connected layer since I'm not taking into any spatial structure -> but going to take the pixel value at every single location = look across channels\n",
        "  - (in channel perspective): we're doing operiations jointly across channels to obtain the output = working with locality across channels\n",
        "  - way to combine multiple channels\n",
        "  - if we only have one channel: having 1*1 patch wouldn't make sense -> but you still have spatial information, if you look at multiple channels but at the same pixel location\n",
        "    - pixel values across different relations may still be related and have spatial structures if they're the same pixel location"
      ],
      "metadata": {
        "id": "tjY5Qm2mc_8Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 19,
        "id": "A04usaJ7l8Fq"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* Multiple channels can be used to extend the model parameters of the convolutional layer.\n",
        "* The $1\\times 1$ convolutional layer is equivalent to the fully-connected layer, when applied on a per pixel basis.\n",
        "* The $1\\times 1$ convolutional layer is typically used to adjust the number of channels between network layers and to control model complexity.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}